project: example_runs
group: 10_scenes
env_id: Nocturne
seed: 42
track_wandb: true
wandb_init_videos: []
where_am_i: headless_machine   # Change to "headless_machine" when you're on a cluster or desktop
exp_name: Nocturne
verbose: 0
psr: false # Prioritized scene replay

wandb:
  sync_tensorboard: true
  save_code: false

ma_callback:
  save_model: true
  save_video: true
  model_save_freq: 200 # In iterations (one iter ~ (num_agents x n_steps))
  record_n_scenes: 15 # Number of different scenes to render
  video_save_freq: 30 # Make a video every k iterations (100 iters ~ 1M steps)
  video_deterministic: true
  eval_freq: 500 # Evaluate full RL task in deterministic mode (turn off intermediate goals)

ppo:
  learning_rate: 3e-4
  policy: MlpPolicy
  n_steps: 4096
  ent_coef: 0.001 # Default in SB3 is 0
  vf_coef: 0.5 # Default in SB3 is 0.5

learn:
  total_timesteps: 10_000_000
  progress_bar: false

# human-regularized RL
reg_weight: 0.0
human_policy_path: models_trained/il/human_policy_D651_S500_02_18_20_05_AV_ONLY.pt # Path to the human reference policy
reg_weight_decay_schedule: None

# Model arch
model_config:
  arch_ro: ''
  arch_rg: ''
  arch_shared: ''
  act_func: ''
  dropout": 0.0
