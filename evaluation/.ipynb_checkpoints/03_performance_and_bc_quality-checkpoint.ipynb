{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How important is the BC policy quality in the effectiveness of HR-PPO?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.policies import load_policy\n",
    "from utils.config import load_config_nb\n",
    "# Load config files\n",
    "from utils.eval import EvaluatePolicy\n",
    "from utils.sb3.reg_ppo import RegularizedPPO\n",
    "import glob\n",
    "import os\n",
    "\n",
    "sns.set(\"notebook\", font_scale=1.12, rc={\"figure.figsize\": (10, 5)})\n",
    "sns.set_style(\"ticks\", rc={\"figure.facecolor\": \"none\", \"axes.facecolor\": \"none\"})\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "plt.set_loglevel(\"WARNING\")\n",
    "mpl.rcParams[\"lines.markersize\"] = 8\n",
    "\n",
    "METRICS_HUMAN_LIKE = ['act_acc', 'accel_val_mae', 'steer_val_mae', 'speed_mae', 'ADE']\n",
    "METRICS_PERFORMANCE = ['goal_rate', 'off_road', 'collision_rate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config files\n",
    "env_config = load_config_nb(\"env_config\")\n",
    "exp_config = load_config_nb(\"exp_config\")\n",
    "video_config = load_config_nb(\"video_config\")\n",
    "models_config = load_config_nb(\"model_bc_quality\") # Trained models\n",
    "\n",
    "# Evaluation settings\n",
    "EVAL_MODE = 'Log-replay'\n",
    "DATASET = '../data/train_no_tl'\n",
    "\n",
    "env_config.data_path = DATASET\n",
    "NUM_EVAL_EPISODES = 50 # Number of episodes to evaluate on\n",
    "DETERMINISTIC = False \n",
    "SELECT_FROM = 50\n",
    "MAX_CONTROLLED_AGENTS = 200 # All agents are controlled\n",
    "\n",
    "# Dataset\n",
    "env_config.data_path = DATASET\n",
    "test_file_paths = glob.glob(f\"{env_config.data_path}\" + \"/tfrecord*\")\n",
    "test_eval_files = sorted([os.path.basename(file) for file in test_file_paths])[:SELECT_FROM]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_quality(goal_rate, coll_rate, off_road):\n",
    "    # Calculate the average of the three inputs\n",
    "    quality_score = (goal_rate + (1 - coll_rate) + (1 - off_road)) / 3\n",
    "    return quality_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating policy_L0.0_IL_0_I1200.zip...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:No regularization weight specified, using default PPO.\n",
      "INFO:root:Using regularization loss: None\n",
      "INFO:root:\n",
      " Evaluating policy on 50 files...\n",
      "100%|██████████| 50/50 [00:17<00:00,  2.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating policy_L0.07_IL_1_I1800.zip...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:No regularization weight specified, using default PPO.\n",
      "INFO:root:Using regularization loss: None\n",
      "INFO:root:\n",
      " Evaluating policy on 50 files...\n",
      "100%|██████████| 50/50 [00:23<00:00,  2.11it/s]\n",
      "INFO:root:No regularization weight specified, using default PPO.\n",
      "INFO:root:Using regularization loss: None\n",
      "INFO:root:\n",
      " Evaluating policy on 50 files...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating policy_L0.07_IL_50_I2927.zip...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:10<00:00,  4.94it/s]\n",
      "INFO:root:No regularization weight specified, using default PPO.\n",
      "INFO:root:Using regularization loss: None\n",
      "INFO:root:\n",
      " Evaluating policy on 50 files...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating policy_L0.07_IL_500_I2600.zip...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:10<00:00,  4.85it/s]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate PPO models\n",
    "df_ppo = pd.DataFrame()\n",
    "\n",
    "PPO_BASE_PATH = f\"../{models_config.hr_ppo_models_dir_self_play}\"\n",
    "\n",
    "for model_config in models_config.trained_models:\n",
    "    \n",
    "    print(f\"Evaluating {model_config.hr_ppo_name}...\")\n",
    "    \n",
    "    # Load policia\n",
    "    ppo_policy = RegularizedPPO.load(\n",
    "        f'{PPO_BASE_PATH}/{model_config.hr_ppo_name}'\n",
    "    )\n",
    "    \n",
    "    # Evaluate policy\n",
    "    ppo_evaluator = EvaluatePolicy(\n",
    "        env_config=env_config,\n",
    "        policy=ppo_policy,\n",
    "        single_agent=True,\n",
    "        eval_files=test_eval_files,\n",
    "        deterministic=DETERMINISTIC,\n",
    "        reg_coef=model_config.reg_weight,\n",
    "    )\n",
    "    df_res = ppo_evaluator._get_scores()\n",
    "            \n",
    "    # Add identifiers\n",
    "    df_res['Agent'] = model_config.agent\n",
    "    df_res['Train agent'] = model_config.train_agent\n",
    "    df_res['Dataset'] = DATASET\n",
    "    df_res['Eval mode'] = EVAL_MODE\n",
    "    df_res['IL policy'] = model_config.il_policy\n",
    "    df_res['IL policy name'] = model_config.il_policy_name\n",
    "    \n",
    "    # Store\n",
    "    df_ppo = pd.concat([df_ppo, df_res], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate BC policies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:\n",
      " Evaluating policy on 50 files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:06<00:00,  7.20it/s]\n",
      "INFO:root:\n",
      " Evaluating policy on 50 files...\n",
      "100%|██████████| 50/50 [00:06<00:00,  7.38it/s]\n",
      "INFO:root:\n",
      " Evaluating policy on 50 files...\n",
      "100%|██████████| 50/50 [00:06<00:00,  7.37it/s]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate PPO models\n",
    "df_il = pd.DataFrame()\n",
    "\n",
    "IL_BASE_PATH = f\"../{models_config.bc_models_dir}\"\n",
    "\n",
    "for model_config in models_config.trained_models:\n",
    "    \n",
    "    # Load policia\n",
    "    if model_config.il_policy_name != None:\n",
    "       \n",
    "        human_policy = load_policy(\n",
    "            data_path=IL_BASE_PATH,\n",
    "            file_name=model_config.il_policy_name, \n",
    "        )\n",
    "        \n",
    "        # Evaluate policy\n",
    "        il_evaluator = EvaluatePolicy(\n",
    "            env_config=env_config,\n",
    "            policy=human_policy,\n",
    "            eval_files=test_eval_files,\n",
    "            single_agent=True,\n",
    "            deterministic=DETERMINISTIC,\n",
    "            reg_coef=model_config.reg_weight,\n",
    "        )\n",
    "        \n",
    "        df_res_il = il_evaluator._get_scores()\n",
    "                \n",
    "        # Add identifiers\n",
    "        df_res_il['Agent'] = model_config.agent\n",
    "        df_res_il['Train agent'] = model_config.train_agent\n",
    "        df_res_il['Dataset'] = DATASET\n",
    "        df_res_il['Eval mode'] = EVAL_MODE\n",
    "        df_res_il['IL policy'] = model_config.il_policy\n",
    "        df_res_il['IL policy name'] = model_config.il_policy_name\n",
    "        \n",
    "        # Store\n",
    "        df_il = pd.concat([df_il, df_res_il], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_il_agg = df_il.groupby(['IL policy'])[METRICS_HUMAN_LIKE+METRICS_PERFORMANCE].mean() \n",
    "df_hr_ppo_agg = df_ppo.groupby(['IL policy'])[METRICS_HUMAN_LIKE+METRICS_PERFORMANCE].mean() \n",
    "\n",
    "df_hr_ppo_agg.reset_index(inplace=True)\n",
    "df_il_agg.reset_index(inplace=True)\n",
    "\n",
    "custom_order = ['0_scenes', '1_scenes', '50_scenes', '200_scenes']\n",
    "\n",
    "# Convert 'IL policy' column to categorical with custom order\n",
    "df_il_agg['IL policy'] = pd.Categorical(df_il_agg['IL policy'], categories=custom_order, ordered=True)\n",
    "df_hr_ppo_agg['IL policy'] = pd.Categorical(df_hr_ppo_agg['IL policy'], categories=custom_order, ordered=True)\n",
    "\n",
    "df_il_agg['total_coll_rate'] = df_il_agg['collision_rate'] + df_il_agg['off_road']\n",
    "df_hr_ppo_agg['total_coll_rate'] = df_hr_ppo_agg['collision_rate'] + df_hr_ppo_agg['off_road']\n",
    "\n",
    "df_hr_ppo_agg['total_coll_rate'] *= 100\n",
    "df_il_agg['total_coll_rate'] *= 100\n",
    "df_hr_ppo_agg['goal_rate'] *= 100\n",
    "df_il_agg['goal_rate'] *= 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams[\"lines.markersize\"] = 11\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(14, 4.5), sharex=True,)\n",
    "\n",
    "# Effectiveness\n",
    "sns.lineplot(\n",
    "    data=df_il_agg,\n",
    "    x='IL policy',\n",
    "    y='goal_rate',\n",
    "    marker='o',\n",
    "    ax=axes[0],\n",
    ")\n",
    "\n",
    "sns.lineplot(\n",
    "    data=df_hr_ppo_agg,\n",
    "    x='IL policy',\n",
    "    y='goal_rate',\n",
    "    marker='^',\n",
    "    ax=axes[0],\n",
    ")\n",
    "\n",
    "# sns.lineplot(\n",
    "#     data=df_il_agg,\n",
    "#     x='IL policy',\n",
    "#     y='total_coll_rate',\n",
    "#     marker='o',\n",
    "#     ax=axes[1],\n",
    "# )\n",
    "\n",
    "# sns.lineplot(\n",
    "#     data=df_hr_ppo_agg,\n",
    "#     x='IL policy',\n",
    "#     y='total_coll_rate',\n",
    "#     marker='^',\n",
    "#     ax=axes[1],\n",
    "# )\n",
    "    \n",
    "# Human-likeness\n",
    "sns.lineplot(\n",
    "    data=df_il_agg,\n",
    "    x='IL policy',\n",
    "    y='ADE',\n",
    "    marker='o',\n",
    "    ax=axes[1],\n",
    ")\n",
    "\n",
    "# Human-likeness\n",
    "sns.lineplot(\n",
    "    data=df_hr_ppo_agg,\n",
    "    x='IL policy',\n",
    "    y='ADE',\n",
    "    marker='^',\n",
    "    ax=axes[1],\n",
    ")\n",
    "\n",
    "# Human-likeness\n",
    "sns.lineplot(\n",
    "    data=df_il_agg,\n",
    "    x='IL policy',\n",
    "    y='accel_val_mae',\n",
    "    marker='o',\n",
    "    ax=axes[2],\n",
    ")\n",
    "\n",
    "# Human-likeness\n",
    "sns.lineplot(\n",
    "    data=df_hr_ppo_agg,\n",
    "    x='IL policy',\n",
    "    y='accel_val_mae',\n",
    "    marker='^',\n",
    "    ax=axes[2],\n",
    ")\n",
    "\n",
    "# Human-likeness\n",
    "sns.lineplot(\n",
    "    data=df_il_agg,\n",
    "    x='IL policy',\n",
    "    y='steer_val_mae',\n",
    "    marker='o',\n",
    "    ax=axes[3],\n",
    "    label='BC',\n",
    ")\n",
    "\n",
    "# Human-likeness\n",
    "sns.lineplot(\n",
    "    data=df_hr_ppo_agg,\n",
    "    x='IL policy',\n",
    "    y='steer_val_mae',\n",
    "    marker='^',\n",
    "    ax=axes[3],\n",
    "    label='(HR-)PPO',\n",
    ")\n",
    "\n",
    "\n",
    "axes[0].set_ylim(0, 100)\n",
    "axes[3].legend(title='Agent', bbox_to_anchor=(1, 1.), loc='upper right', fontsize=12)\n",
    "axes[2].set_title('Realism (↓ is better)')\n",
    "axes[3].set_title('Realism (↓ is better)')\n",
    "axes[0].grid(True, alpha=0.5)\n",
    "axes[1].grid(True, alpha=0.5)\n",
    "axes[2].grid(True, alpha=0.5)\n",
    "axes[3].grid(True, alpha=0.5)\n",
    "axes[0].set_ylabel('')\n",
    "axes[1].set_xlabel('')\n",
    "axes[2].set_xlabel('')\n",
    "axes[3].set_xlabel('')\n",
    "axes[1].set_ylabel('')\n",
    "axes[2].set_ylabel('')\n",
    "axes[3].set_ylabel('')\n",
    "axes[3].set_title(r'$\\bf{Realism}$ | $MAE_{steer}$ (↓)', fontsize=12)\n",
    "axes[1].set_title(r'$\\bf{Realism}$ | ADE (↓)', fontsize=12)\n",
    "axes[2].set_title(r'$\\bf{Realism}$ | $MAE_{accel}$ (↓)', fontsize=12)\n",
    "axes[0].set_title(r'$\\bf{Effectiveness}$ | Goal rate [%]', fontsize=12)\n",
    "axes[0].tick_params(axis='x', rotation=70)\n",
    "axes[1].tick_params(axis='x', rotation=70)\n",
    "axes[2].tick_params(axis='x', rotation=70)\n",
    "axes[3].tick_params(axis='x', rotation=70)\n",
    "axes[0].set_xlabel(' ')\n",
    "\n",
    "axes[0].set_xticks(custom_order, ['PPO', 'HR-PPO: 1 S', 'HR-PPO: 50 S', 'HR-PPO: 200 S'])\n",
    "\n",
    "plt.tight_layout()\n",
    "# sns.lineplot(data=df_il_agg, x='IL policy', y='goal_rate', order=[], marker='o');\n",
    "# sns.lineplot(data=df_hr_ppo_agg, x='IL policy', y='goal_rate', marker='o');\n",
    "\n",
    "plt.savefig(f'bc_quality.pdf', bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nocturne_lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
